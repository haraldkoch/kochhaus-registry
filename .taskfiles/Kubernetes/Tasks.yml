---
version: "3"

tasks:

  kubeconfig:
    desc: Download kubeconfig from a remote k3s master node
    vars:
      MASTER_USERNAME: '{{.MASTER_USERNAME | default "root"}}'
      MASTER_HOST: '{{.MASTER_HOST | default "192.168.20.19"}}'
      KUBERNETES_API: '{{.KUBERNETES_API | default "192.168.20.1"}}'
    cmds:
      - rsync --verbose --progress --partial --rsync-path="sudo -E rsync" {{.MASTER_USERNAME}}@{{.MASTER_HOST}}:/etc/rancher/k3s/k3s.yaml "${KUBECONFIG}"
      - sed -i '' 's/127.0.0.1/{{.KUBERNETES_API}}/g' "${KUBECONFIG}"
      - chmod go-r "${KUBECONFIG}"

  schemas:
    desc: Pull the latest CRD schemas for this cluster
    cmds:
      - |
        mkdir -p {{.CLUSTER_DIR}}/schemas
        flux pull artifact oci://ghcr.io/onedr0p/kubernetes-schemas-oci:latest \
            --output={{.CLUSTER_DIR}}/schemas

  list-dockerhub:
    desc: What dockerhub images are running in my cluster
    cmds:
      - kubectl get pods --all-namespaces -o=jsonpath="{range .items[*]}{'\n'}{range .spec.containers[*]}{.image}{'\n'}{end}{end}" | sort | uniq | grep -Ev 'quay|gcr|ghcr|ecr|us-docker|registry.k8s' | grep -Ev 'bitnami|rook|intel|grafana' |  sed -e 's/docker\.io\///g' | sort | uniq

  delete-failed-pods:
    desc: Deletes failed pods
    cmds:
      - kubectl delete pods --field-selector status.phase=Failed -A --ignore-not-found=true

  delete-jobs:
    desc: Delete all jobs
    cmds:
      - kubectl delete job -A --all

  mount:
    desc: Mount a PersistentVolumeClaim to a pod temporarily
    interactive: true
    vars:
      claim: '{{ or .claim (fail "PersistentVolumeClaim `claim` is required") }}'
      namespace: '{{.namespace | default "default"}}'
    cmds:
      - |
        kubectl run -n {{.namespace}} debug-{{.claim}} -i --tty --rm --image=null --privileged --overrides='
          {
            "apiVersion": "v1",
            "spec": {
              "containers": [
                {
                  "name": "debug",
                  "image": "ghcr.io/haraldkoch/alpine:rolling",
                  "command": [
                    "/bin/bash"
                  ],
                  "stdin": true,
                  "stdinOnce": true,
                  "tty": true,
                  "volumeMounts": [
                    {
                      "name": "config",
                      "mountPath": "/data/config"
                    }
                  ]
                }
              ],
              "volumes": [
                {
                  "name": "config",
                  "persistentVolumeClaim": {
                    "claimName": "{{.claim}}"
                  }
                }
              ],
              "restartPolicy": "Never"
            }
          }'
    preconditions:
      - kubectl -n {{.namespace}} get pvc {{.claim}}

  network:
    desc: Create a netshoot container for debugging
    cmds:
      - kubectl run netshoot --rm -i --tty --image ghcr.io/nicolaka/netshoot:latest {{.CLI_ARGS}}

  node:
    desc: |-
      Create a privileged container on a node for debugging (ex. task NODE=k8s-0 debug:node)
    interactive: true
    cmds:
      - |
        kubectl run debug-{{.NODE}} -i --tty --rm --image="docker.io/library/alpine:3.16" --privileged --overrides='
          {
            "spec": {
              "nodeSelector": {
                "kubernetes.io/hostname": "{{.NODE}}"
              },
              "restartPolicy": "Never"
            }
          }'
